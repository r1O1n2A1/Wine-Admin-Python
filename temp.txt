# res = es.search(
  #     config.es_base_url['index'],
  #     body={"query": {"match_all":{}}},
  #     size=0
  #     )
  # s = Search(using=es, index=config.es_base_url['index'])
  # s = s.source([])
  # ids = [h.meta.id for h in s.scan()]

  # for hit in s.scan():
  #     if hasattr(hit, 'user'):
  #         users = hit.user[0]
  # ids = [h.meta.id for h in s.scan()]
  # print(ids)
  # hits = res['hits']['total']
  # print ('Processing {} documents'.format(hits))

  try:
          CatalogParsingQueries('dashboard_parseHitsES').main_parsing()
      except customException.CustomError as customError:
          returnStr = 'query ES can not be processed: ' + str(customError)
      if returnStr != '':
          return returnStr


18839

user.inscription": {
          "gte": "1491078676",
          "lte": "1493670676"
      }

      '/home/ronan/Documents/BigData/spark/spark-2.0.2/bin/spark-submit'
      --jars /home/ronan/Documents/BigData/elasticSearch/elasticsearch-hadoop-5.4.0/dist/elasticsearch-hadoop-5.4.0.jar ~/Project1AL/Wine-Admin-Python/pysparkImportTest.py 
